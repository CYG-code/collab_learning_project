import asyncio
import os
import chainlit as cl
from dotenv import load_dotenv

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.teams import SelectorGroupChat
from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination

from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import ModelInfo

load_dotenv()

# ==========================================
# 1. åŸºç¡€é…ç½® (ä» .env è¯»å–çµèŠ½é…ç½®)
# ==========================================
api_key = os.environ.get("LINGYA_API_KEY")
base_url = "https://api.lingyaai.cn/v1"
custom_model_info = ModelInfo(vision=False, function_calling=True, json_output=False, family="unknown")

planner_model = OpenAIChatCompletionClient(
    model="gemini-3.1-pro-preview", api_key=api_key, base_url=base_url, model_info=custom_model_info
)
facilitator_model = OpenAIChatCompletionClient(
    model="gpt-4o-mini", api_key=api_key, base_url=base_url, model_info=custom_model_info
)

# ==========================================
# 2. ç½‘é¡µåˆ·æ–°æ—¶çš„åˆå§‹åŒ–åŠ¨ä½œ
# ==========================================
@cl.on_chat_start
async def start_chat():
    # å®šä¹‰ AI è§’è‰²
    planner = AssistantAgent(
        name="Planner",
        model_client=planner_model,
        system_message="""ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®è§„åˆ’å¸ˆã€‚
        ä½ çš„èŒè´£æ˜¯å¸®åŠ©å­¦ç”Ÿæ‹†è§£å¤æ‚çš„éš¾é¢˜ã€‚ä½ è¦é€»è¾‘æ¸…æ™°ï¼Œç›´æ¥ç»™å‡ºç»“æ„åŒ–çš„å»ºè®®ã€‚
        å½“ä½ è§‰å¾—å½“å‰é˜¶æ®µçš„è§„åˆ’å·²ç»ç»™å®Œï¼Œéœ€è¦ç­‰å¾…å­¦ç”Ÿæ€è€ƒæˆ–åé¦ˆæ—¶ï¼Œè¯·åœ¨å›å¤çš„æœ€æœ«å°¾åŠ ä¸Š 'WAIT' ç»“æŸæœ¬è½®å‘è¨€ã€‚"""
    )

    facilitator = AssistantAgent(
        name="Facilitator",
        model_client=facilitator_model,
        system_message="""ä½ æ˜¯ä¸€ä¸ªåä½œå­¦ä¹ çš„å¼•å¯¼è€…ã€‚
        æ³¨æ„ï¼šå°½é‡ä¿æŒé™é»˜ï¼åªæœ‰å½“å­¦ç”Ÿæ€è·¯å¡å£³ï¼Œæˆ–è€…ä¸»åŠ¨å‘ä½ æ±‚åŠ©æ—¶ï¼Œä½ æ‰å‘è¨€ã€‚
        ç»å¯¹ä¸è¦ç›´æ¥ç»™å‡ºç­”æ¡ˆã€‚ç”¨è‹æ ¼æ‹‰åº•å¼çš„æé—®ï¼Œå¯å‘å­¦ç”Ÿè‡ªå·±æ€è€ƒã€‚
        å½“ä½ çš„æé—®ç»“æŸåï¼Œè¯·åœ¨å›å¤çš„æœ€æœ«å°¾åŠ ä¸Š 'WAIT' ç»“æŸæœ¬è½®å‘è¨€ã€‚"""
    )

    # ç»ˆæ­¢æ¡ä»¶ï¼šå½“ AI è¯´ WAITï¼Œæˆ–è€…å¯¹è¯è¶…è¿‡3è½®ï¼ˆé˜²æ­¢ AI ä¹‹é—´æ²¡å®Œæ²¡äº†åœ°äº’èŠï¼‰
    termination = TextMentionTermination("WAIT") | MaxMessageTermination(max_messages=3)

    # åˆ›å»ºç¾¤èŠ (å‰”é™¤ UserProxyAgentï¼Œç”±ç½‘é¡µè¾“å…¥æ¥ç®¡ç”¨æˆ·å‘è¨€)
    team = SelectorGroupChat(
        participants=[planner, facilitator],
        model_client=planner_model, 
        termination_condition=termination,
    )
    
    # å°†åˆ›å»ºå¥½çš„å›¢é˜Ÿå­˜å…¥å½“å‰ç”¨æˆ·çš„ç½‘é¡µ Session ä¸­
    cl.user_session.set("team", team)
    
    # åœ¨ç½‘é¡µç«¯å‘é€æ¬¢è¿è¯­
    await cl.Message(
        content="ğŸš€ **åä½œå­¦ä¹ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå·²å¯åŠ¨ï¼**\n\næˆ‘æ˜¯åå°ç³»ç»Ÿã€‚ç°åœ¨ `Planner` å’Œ `Facilitator` å·²ç»è¿›å…¥äº†èŠå¤©å®¤ã€‚ä½ å¯ä»¥æŠŠä½ çš„è¯¾é¢˜å‘å‡ºæ¥äº†ï¼ˆæ¯”å¦‚ï¼š*å¦‚ä½•ç”¨åºŸæ—§å®‰å“æ‰‹æœºæ­æœåŠ¡å™¨ï¼Ÿ*ï¼‰",
        author="System"
    ).send()

# ==========================================
# 3. å¤„ç†ç”¨æˆ·åœ¨ç½‘é¡µç«¯çš„è¾“å…¥
# ==========================================
@cl.on_message
async def main(message: cl.Message):
    # ä» Session ä¸­å–å‡ºåˆšæ‰åˆå§‹åŒ–çš„å›¢é˜Ÿ
    team = cl.user_session.get("team")
    
    # å°†ç”¨æˆ·åœ¨ç½‘é¡µçš„è¾“å…¥å‘ç»™ AI ç¾¤èŠï¼Œå¹¶å®æ—¶æ•è·å®ƒä»¬çš„è®¨è®ºæµ
    async for msg in team.run_stream(task=message.content):
        
        # è¿‡æ»¤å‡ºåŒ…å«çœŸå®æ–‡æœ¬å†…å®¹çš„å›å¤
        if hasattr(msg, 'content') and isinstance(msg.content, str):
            # å¿½ç•¥ç³»ç»Ÿå›æ˜¾
            if msg.source != "user" and msg.content.strip():
                # æ¸…ç†æ‰è§¦å‘è¯ WAITï¼Œè®©ç½‘é¡µç•Œé¢æ›´ç¾è§‚
                display_text = msg.content.replace("WAIT", "").strip()
                
                # å°† AI çš„å›å¤æ¨é€åˆ°ç½‘é¡µä¸Šæ˜¾ç¤ºï¼Œå¹¶æ ‡æ³¨æ˜¯å“ªä¸ªè§’è‰²çš„å‘è¨€
                await cl.Message(content=display_text, author=msg.source).send()